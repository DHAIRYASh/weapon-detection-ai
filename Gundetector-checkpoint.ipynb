{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the value\n",
      "Enter the number on the basis of the operation you want to perform1\n",
      "GUNS DETECTED\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import imutils\n",
    "import datetime\n",
    "import os\n",
    "import pandas as pd\n",
    "import time as t\n",
    "import argparse as ap\n",
    "\n",
    "def knifesissorstruck():\n",
    "    argument_parser = ap.ArgumentParser()\n",
    "    argument_parser.add_argument(\"-i\", \"--image\", required=True,help=\"path to input image\")\n",
    "    argument_parser.add_argument(\"-c\", \"--confidence\", type=float, default=0.5,help=\"minimum probability to filter weak detections\")\n",
    "    argument_parser.add_argument(\"-y\", \"--yolo\", required=True,\thelp=\"base path to YOLO directory\")\n",
    "    argument_parser.add_argument(\"-t\", \"--threshold\", type=float, default=0.3,help=\"threshold when applyong non-maxima suppression\")\n",
    "    args = vars(argument_parser.parse_args())\n",
    "    # loading the COCO class labels on which our YOLO model was trained\n",
    "    labels_path = os.path.sep.join([args[\"yolo\"], \"coco.names\"])\n",
    "    LABELS = open(labels_path).read().strip().split(\"\\n\")\n",
    "    # for representation of each possible class label we initialize the list of colors\n",
    "    np.random.seed(42)\n",
    "    #the random the seed specified in the abovoe line\n",
    "    COLORS = np.random.randint(0, 255, size=(len(LABELS), 3),dtype=\"uint8\")\n",
    "    # deriving the paths to the YOLO weights and model configuration\n",
    "    # deriving the paths to the YOLO weights and model configuration\n",
    "    weights_path = os.path.sep.join([args[\"yolo\"], \"yolov3.weights\"])\n",
    "    config_path = os.path.sep.join([args[\"yolo\"], \"yolov3.cfg\"])\n",
    "    # loading our YOLO object detector trained on the COCO dataset\n",
    "    print(\"[INFO] loading YOLO from disk...\")\n",
    "    net = cv2.dnn.readNetFromDarknet(config_path, weights_path)\n",
    "    # loading our input image and grab its spatial dimensions\n",
    "    image = cv2.imread(args[\"image\"])\n",
    "    (H, W) = image.shape[:2]\n",
    "    # determine only the *output* layer names that we need from YOLO\n",
    "    ln = net.getLayerNames()\n",
    "    ln = [ln[i[0] - 1] for i in net.getUnconnectedOutLayers()]\n",
    "    # construct a blob from the input image and performing a forward pass of the YOLO object detector\n",
    "    # this process gives us the bounding boxes and associated probabilities\n",
    "    blob = cv2.dnn.blobFromImage(image, 1 / 255.0, (416, 416),swapRB=True, crop=True)\n",
    "    net.setInput(blob)\n",
    "    start = t.time()\n",
    "    layerOutputs = net.forward(ln)\n",
    "    end = t.time()\n",
    "    # show timing information on YOLO\n",
    "    print(\"[INFO] YOLO took {:.2f} seconds\".format(end - start))\n",
    "    # initialize our lists of detected bounding boxes, confidences, and class ids\n",
    "    boxes = []\n",
    "    confidences = []\n",
    "    class_ids = []\n",
    "    # loop over each of the layer outputs\n",
    "    for output in layerOutputs:\n",
    "        # loop over each of the detections\n",
    "        for detection in output:\n",
    "            # extract the class id and confidence of the current object detection\n",
    "            scores = detection[5:]\n",
    "            classID = np.argmax(scores)\n",
    "            confidence = scores[classID]\n",
    "            # filter out the weak predictions by ensuring the detected probability is greater than the minimum probability\n",
    "            if confidence > args[\"confidence\"]:\n",
    "                # scale the bounding box coordinates back relative to the size of the image, keeping in mind that YOLO actually\n",
    "                # returns the center (x, y)-coordinates of the bounding box followed by the boxe's width and height\n",
    "                box = detection[0:4] * np.array([W, H, W, H])\n",
    "                (centerX, centerY, width, height) = box.astype(\"int\")\n",
    "                # use the center (x, y)-coordinates to derive the top and left corner of the bounding box\n",
    "                x = int(centerX - (width / 2))\n",
    "                y = int(centerY - (height / 2))\n",
    "                # update our list of bounding box coordinates, confidences and class ids\n",
    "                boxes.append([x, y, int(width), int(height)])\n",
    "                confidences.append(float(confidence))\n",
    "                class_ids.append(classID)\n",
    "    # apply non-maxima suppression to suppress weak, overlapping bounding boxes\n",
    "    indexes = cv2.dnn.NMSBoxes(boxes, confidences, args[\"confidence\"],\n",
    "\targs[\"threshold\"])\n",
    "    # ensure at least one detection exists\n",
    "    if len(indexes) > 0:\n",
    "        # loop over the indexes we are keeping\n",
    "        for i in indexes.flatten():\n",
    "            # extract the bounding box coordinates\n",
    "            (x, y) = (boxes[i][0], boxes[i][1])\n",
    "            (w, h) = (boxes[i][2], boxes[i][3])\n",
    "            # draw a rectangle bounding box and label on the image\n",
    "            color = [int(c) for c in COLORS[class_ids[i]]]\n",
    "            cv2.rectangle(image, (x, y), (x + w, y + h), color, 2)\n",
    "            text = \"{}: {:.2f}\".format(LABELS[class_ids[i]], confidences[i])\n",
    "            cv2.putText(image, text, (x, y - 2), cv2.FONT_HERSHEY_SIMPLEX,0.5, color, 1)\n",
    "    # display the output image\n",
    "    cv2.imshow(\"Output Image\", image)\n",
    "    cv2.waitKey(0)\n",
    "\n",
    "\n",
    "\n",
    "def gundetector():\n",
    "    gun_exist = False\n",
    "    firstFrame = None\n",
    "    camera = cv2.VideoCapture(\"data/video.mp4\")\n",
    "    gun_cascade = cv2.CascadeClassifier(\"cascade.xml\")\n",
    "    while True:\n",
    "        (grabbed,frame)=camera.read()\n",
    "        if not grabbed:\n",
    "          break\n",
    "        frame = imutils.resize(frame, width=500)\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        gray = cv2.GaussianBlur(gray, (21, 21), 0)\n",
    "        gun = gun_cascade.detectMultiScale(gray, 1.3, 5, minSize = (100, 100))\n",
    "        if len(gun) >  0:\n",
    "            gun_exist = True\n",
    "        for (x,y,w,h) in gun:\n",
    "            frame = cv2.rectangle (frame, (x,y), (x+w, y+h), (255,0,0), 2)\n",
    "            roi_gray = gray[y: y+h, x:x+w]\n",
    "            roi_color = frame[y:y+h, x+w]\n",
    "        if firstFrame is None:\n",
    "            firstFrame = gray\n",
    "            continue\n",
    "        cv2.putText(frame, datetime.datetime.now().strftime('%A %d %B %Y %I:%M:%S%p'),(10, frame.shape[0] - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.35, (0, 0, 255), 1)\n",
    "        cv2.imshow('Security Feed', frame)\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "    if gun_exist:\n",
    "        print('GUNS DETECTED')\n",
    "    else:\n",
    "        print('GUNS NOT DETECTED')\n",
    "    camera.release()\n",
    "    cv2.destroyAllWindows()\n",
    "print(\"=================================EXECUTION OF THE PROJECT======================================\")\n",
    "print(\"====================================1. TO DETECT THE GUN FROM THE VIDEO========================\")\n",
    "print(\"====================================2. TO DETECT THE KNIFE, SISSORS AND Truck FROM THE VIDEO========================\")\n",
    "number1=int(input(\"Enter the number on the basis of the operation you want to perform\"))\n",
    "if(number1==1):\n",
    "    gundetector()\n",
    "if(number1==2):\n",
    "    knifesissorstruck()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
